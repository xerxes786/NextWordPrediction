{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a19d3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c5a6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Fake.csv')\n",
    "df2 = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78f51808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebb82ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3af1a96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "609b3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(df.text.values)\n",
    "full_text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "447c4fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110902984"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f4b950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = full_text[:1000000] #18679895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2633f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(full_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f9f36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_tokens_index = {token:indx for indx,token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ef0548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_words = []\n",
    "\n",
    "for i in range(len(tokens)-n_words):\n",
    "    input_words.append(tokens[i:i+n_words])\n",
    "    next_words.append(tokens[i+n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec080615",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
    "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "005b2cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17221, 3596)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67beb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,words in enumerate(input_words):\n",
    "    for j,word in enumerate(words):\n",
    "        x[i,j,unique_tokens_index[word]]=1\n",
    "    y[i, unique_tokens_index[next_words[i]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "787a5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape = (n_words,len(unique_tokens)),return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3742239",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5cec1ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "270/270 [==============================] - 34s 115ms/step - loss: 7.1449 - accuracy: 0.0452\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 31s 116ms/step - loss: 6.7560 - accuracy: 0.0457\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 32s 119ms/step - loss: 6.7264 - accuracy: 0.0457\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 36s 133ms/step - loss: 6.6577 - accuracy: 0.0457\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 35s 129ms/step - loss: 6.6502 - accuracy: 0.0452\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 34s 127ms/step - loss: 6.5117 - accuracy: 0.0479\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 34s 125ms/step - loss: 6.3769 - accuracy: 0.0522\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 34s 125ms/step - loss: 6.2173 - accuracy: 0.0566\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 34s 125ms/step - loss: 6.0399 - accuracy: 0.0620\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 34s 124ms/step - loss: 5.8825 - accuracy: 0.0656\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 33s 124ms/step - loss: 5.7219 - accuracy: 0.0714\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 31s 114ms/step - loss: 5.5634 - accuracy: 0.0803\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 32s 118ms/step - loss: 5.4046 - accuracy: 0.0886\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 32s 120ms/step - loss: 5.2453 - accuracy: 0.0997\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 34s 126ms/step - loss: 5.0906 - accuracy: 0.1104\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 34s 128ms/step - loss: 4.9423 - accuracy: 0.1210\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 31s 114ms/step - loss: 4.7980 - accuracy: 0.1350\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 30s 113ms/step - loss: 4.6740 - accuracy: 0.1482\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 31s 114ms/step - loss: 4.5393 - accuracy: 0.1599\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 32s 117ms/step - loss: 4.4141 - accuracy: 0.1720\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 34s 126ms/step - loss: 4.2993 - accuracy: 0.1872\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 33s 121ms/step - loss: 4.1600 - accuracy: 0.2022\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 33s 122ms/step - loss: 4.0439 - accuracy: 0.2190\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 30s 111ms/step - loss: 3.9235 - accuracy: 0.2317\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 31s 116ms/step - loss: 3.8001 - accuracy: 0.2495\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 34s 125ms/step - loss: 3.6915 - accuracy: 0.2618\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 34s 125ms/step - loss: 3.5920 - accuracy: 0.2740\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 34s 128ms/step - loss: 3.4729 - accuracy: 0.2926\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 36s 132ms/step - loss: 3.3805 - accuracy: 0.3063\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 36s 132ms/step - loss: 3.2876 - accuracy: 0.3200\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 36s 133ms/step - loss: 3.1720 - accuracy: 0.3384\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 33s 121ms/step - loss: 3.0783 - accuracy: 0.3507\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 30s 113ms/step - loss: 2.9750 - accuracy: 0.3709\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 31s 113ms/step - loss: 2.8702 - accuracy: 0.3910\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 30s 112ms/step - loss: 2.7668 - accuracy: 0.4112\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 30s 112ms/step - loss: 2.6713 - accuracy: 0.4291\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 32s 118ms/step - loss: 2.6107 - accuracy: 0.4418\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 30s 112ms/step - loss: 2.5216 - accuracy: 0.4587\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 45s 165ms/step - loss: 2.4173 - accuracy: 0.4833\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 52s 194ms/step - loss: 2.3147 - accuracy: 0.5083\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 50s 185ms/step - loss: 2.2273 - accuracy: 0.5298\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 50s 185ms/step - loss: 2.1353 - accuracy: 0.5513\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 55s 203ms/step - loss: 2.0602 - accuracy: 0.5620\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 54s 200ms/step - loss: 1.9921 - accuracy: 0.5792\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 51s 187ms/step - loss: 1.8982 - accuracy: 0.6043\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 53s 195ms/step - loss: 1.8209 - accuracy: 0.6237\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 53s 196ms/step - loss: 1.7615 - accuracy: 0.6345\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 53s 197ms/step - loss: 1.7047 - accuracy: 0.6501\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 53s 196ms/step - loss: 1.6314 - accuracy: 0.6623\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 53s 198ms/step - loss: 1.5456 - accuracy: 0.6896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24731bf2d70>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8b5d4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text,n_best):\n",
    "    input_text = input_text.lower()\n",
    "    x = np.zeros((1,20,len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        x[0, i, unique_tokens_index[word]]=1\n",
    "    prediction = model.predict(x)[0]\n",
    "    return np.argpartition(prediction, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "088694fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text,text_lenght, creativity=3):\n",
    "    word_seq = input_text.split()\n",
    "    current = 0\n",
    "    for i in range(text_lenght):\n",
    "        sub_seq = \" \".join(tokenizer.tokenize(\" \".join(word_seq).lower()[current:current+n_words]))\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict(sub_seq, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_seq.append(choice)\n",
    "        current = current+1\n",
    "    return \" \".join(word_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4add6dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to see what is possible in this world and want to visit countries like India and dubai and placed durbin school thanking collection'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"I want to see what is possible in this world and want to visit countries like India and dubai and\",5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29825a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
